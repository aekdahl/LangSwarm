version: "1.0"
project_name: "distributed_task_processing_complete"

# Complete distributed task processing setup with both producer and consumer
memory: "production"

tools:
  # Message queue publisher (for sending tasks)
  - id: task_publisher
    type: mcpmessage_queue_publisher
    description: "Publish tasks to message queues"

  # Message queue consumer (for processing tasks)
  - id: task_consumer
    type: mcpmessage_queue_consumer
    description: "Consume and process tasks from message queues"

  # Workflow executor (for complex task processing)
  - id: workflow_executor
    type: mcpworkflow_executor
    description: "Execute workflows for complex task processing"

agents:
  # Task Coordinator - orchestrates the entire pipeline
  - id: task_coordinator
    agent_type: openai
    model: gpt-4o
    system_prompt: |
      You are a Task Coordinator that orchestrates distributed task processing.
      
      Your role:
      1. **Task Publishing**: Send tasks to queues using task_publisher
      2. **Consumer Management**: Start/stop consumers using task_consumer
      3. **Workflow Integration**: Execute complex workflows using workflow_executor
      4. **System Monitoring**: Monitor overall system health and performance
      
      **Complete Task Processing Flow:**
      1. Receive task requests from users
      2. Determine appropriate queue and task format
      3. Publish tasks to message queue
      4. Ensure consumers are running to process tasks
      5. Monitor processing and provide status updates
      
      **Task Types You Handle:**
      - Simple data processing tasks
      - Complex workflow execution tasks
      - File processing and analysis
      - API integration tasks
      - Custom business logic tasks
      
      Use all available tools to provide comprehensive task processing capabilities.
    
    tools:
      - task_publisher
      - task_consumer
      - workflow_executor

  # Redis Task Manager - specialized for Redis operations
  - id: redis_task_manager
    agent_type: openai
    model: gpt-4o
    system_prompt: |
      You are a Redis Task Manager specialized in Redis-based distributed processing.
      
      **Redis Expertise:**
      - Optimal Redis consumer configuration
      - Redis queue management and monitoring
      - Performance tuning for Redis workloads
      - Redis connection and authentication handling
      
      **Typical Redis Configuration:**
      ```json
      {
        "consumer_id": "redis_worker",
        "broker_type": "redis",
        "broker_config": {
          "redis_url": "redis://localhost:6379"
        },
        "queue_name": "redis_tasks",
        "max_workers": 5,
        "poll_interval": 1
      }
      ```
      
      Focus on Redis-specific optimizations and best practices.
    
    tools:
      - task_publisher
      - task_consumer

  # Enterprise Task Manager - for production-grade processing
  - id: enterprise_task_manager
    agent_type: openai
    model: gpt-4o
    system_prompt: |
      You are an Enterprise Task Manager for production-grade distributed processing.
      
      **Enterprise Focus:**
      - GCP Pub/Sub integration for guaranteed delivery
      - High-availability consumer configurations
      - Performance monitoring and optimization
      - Scaling strategies for enterprise workloads
      
      **Enterprise Configuration:**
      ```json
      {
        "consumer_id": "enterprise_worker",
        "broker_type": "gcp_pubsub",
        "broker_config": {
          "project_id": "enterprise-project"
        },
        "queue_name": "enterprise-tasks",
        "max_workers": 15,
        "retry_attempts": 5,
        "task_timeout": 600
      }
      ```
      
      Ensure enterprise-grade reliability, monitoring, and performance.
    
    tools:
      - task_publisher
      - task_consumer
      - workflow_executor

  # Development Task Tester - for testing and validation
  - id: dev_task_tester
    agent_type: openai
    model: gpt-4o
    system_prompt: |
      You are a Development Task Tester for validating distributed task processing.
      
      **Testing Responsibilities:**
      - Use in-memory queues for rapid testing
      - Validate task publishing and consumption flow
      - Test different task types and scenarios
      - Verify error handling and retry logic
      
      **Test Configuration:**
      ```json
      {
        "consumer_id": "test_consumer",
        "broker_type": "in_memory",
        "broker_config": {},
        "queue_name": "test_queue",
        "max_workers": 2
      }
      ```
      
      **Testing Scenarios:**
      1. Publish test tasks and verify consumption
      2. Test consumer pause/resume functionality
      3. Validate error handling and retries
      4. Monitor performance metrics
      
      Focus on comprehensive testing before production deployment.
    
    tools:
      - task_publisher
      - task_consumer

workflows:
  # Complete task processing pipeline
  distributed_task_pipeline:
    description: "Complete distributed task processing from publishing to execution"
    steps:
      - agent: task_coordinator
        input: "${user_input}"
        output:
          to: user

  # Redis-focused task processing
  redis_task_processing:
    description: "Redis-based task processing with optimal configuration"
    steps:
      - agent: redis_task_manager
        input: "${user_input}"
        output:
          to: user

  # Enterprise task processing
  enterprise_task_processing:
    description: "Enterprise-grade task processing with GCP Pub/Sub"
    steps:
      - agent: enterprise_task_manager
        input: "${user_input}"
        output:
          to: user

  # Development testing
  test_task_processing:
    description: "Test and validate task processing functionality"
    steps:
      - agent: dev_task_tester
        input: "${user_input}"
        output:
          to: user

  # End-to-end task processing workflow
  complete_task_lifecycle:
    description: "Manage complete task lifecycle from creation to completion"
    steps:
      - agent: task_coordinator
        input: "Set up task processing: ${user_input}"
        
      - agent: redis_task_manager
        input: "Configure Redis consumers: ${task_coordinator.output}"
        
      - agent: enterprise_task_manager
        input: "Configure enterprise consumers: ${task_coordinator.output}"
        
      - agent: task_coordinator
        input: "Monitor and coordinate: Redis: ${redis_task_manager.output}, Enterprise: ${enterprise_task_manager.output}"
        output:
          to: user

  # Performance optimization workflow
  optimize_task_processing:
    description: "Analyze and optimize task processing performance"
    steps:
      - agent: task_coordinator
        input: "Analyze current performance: ${user_input}"
        
      - agent: redis_task_manager
        input: "Optimize Redis performance: ${task_coordinator.output}"
        
      - agent: enterprise_task_manager
        input: "Optimize enterprise performance: ${task_coordinator.output}"
        output:
          to: user

  # Scaling workflow
  scale_task_processing:
    description: "Scale task processing capacity based on demand"
    steps:
      - agent: task_coordinator
        input: "Assess scaling needs: ${user_input}"
        
      - agent: enterprise_task_manager
        input: "Implement scaling strategy: ${task_coordinator.output}"
        output:
          to: user

# Example usage scenarios:

# 1. Complete Task Processing Setup:
# "Set up distributed task processing with Redis for fast tasks and GCP Pub/Sub for enterprise tasks"

# 2. Task Publishing and Processing:
# "Publish data analysis tasks to the queue and start consumers to process them"

# 3. Performance Monitoring:
# "Show me the performance statistics for all running consumers and optimize if needed"

# 4. Scaling Operations:
# "Scale up task processing capacity to handle increased workload"

# 5. Development Testing:
# "Test the complete task processing pipeline with sample tasks"
---
title: "Quickstart"
description: "Build your first AI agent in 30 seconds"
---

# ‚ö° LangSwarm Quickstart

**Build your first AI agent and multi-agent system with minimal effort.**

## üöÄ **30-Second Setup**

### **Step 1: Install LangSwarm**
```bash
pip install langswarm openai
```

### **Step 2: Set Your API Key**
```bash
export OPENAI_API_KEY="your-api-key-here"
```

### **Step 3: Create Your First Agent**

#### **Option A: Pure Python Approach (Simplest)**

```python
import asyncio
from langswarm.core.agents import create_openai_agent

async def main():
    # Create an AI agent
    agent = create_openai_agent(
        model="gpt-4o",  # or gpt-3.5-turbo for cost efficiency
    )
    
    # Chat with it
    response = await agent.chat("Hello! What can you do?")
    print(f"AI: {response.content}")

if __name__ == "__main__":
    asyncio.run(main())
```

#### **Option B: Configuration File Approach (Scalable)**

Create `langswarm.yaml`:
```yaml
version: "2.0"
agents:
  - id: "assistant"
    name: "My Assistant"
    provider: "openai"
    model: "gpt-4o"
    system_prompt: "You are a helpful AI assistant."
```

Run it:
```python
from langswarm.core.config import load_config

# Load configuration
config = load_config('langswarm.yaml')
print(f'‚úÖ Loaded {len(config.agents)} agents successfully!')

# Get the agent
agent = config.get_agent_instance("assistant")
response = await agent.chat("Hello!")
print(f"Agent: {response.content}")
```

---

## üéØ **The 80% Use Case: Chatbot with Memory**

Most users want a chatbot that remembers the conversation. Here's how to do it in one minute:

```python
import asyncio
from langswarm.core.agents import AgentBuilder

async def main():
    # Create agent with memory
    agent = (AgentBuilder()
             .openai()
             .model("gpt-4o")
             .memory_enabled(True)  # PERSISTENT memory
             .system_prompt("You are a helpful assistant named Claude.")
             .build())
    
    # Multi-turn conversation
    print("Chatbot: Hello! I'm Claude. How can I help you?")
    
    while True:
        user_input = input("\nYou: ")
        if user_input.lower() in ['quit', 'exit']:
            break
            
        response = await agent.chat(user_input)
        print(f"\nChatbot: {response.content}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## üî• **Advanced Features in 30 Seconds**

### **1. Real-time Streaming**
```python
# Stream response as it's generated
async for chunk in agent.chat_stream("Tell me a story"):
    print(chunk.content, end="", flush=True)
```

### **2. Cost & Token Tracking**
```python
# Track usage automatically
stats = agent.get_usage_stats()
print(f"Total cost: ${stats['estimated_cost']:.4f}")
print(f"Tokens used: {stats['total_tokens']}")
```

### **3. Support for Any Model**
```python
# Anthropic Claude
agent = AgentBuilder().anthropic().model("claude-3-5-sonnet-20240620").build()

# Google Gemini
agent = AgentBuilder().gemini().model("gemini-1.5-pro").build()

# Local Model (via LiteLLM/Ollama)
agent = AgentBuilder().litellm().model("ollama/llama3").build()
```

---

## üêù **The "Swarm" in LangSwarm: Multi-Agent Orchestration**

The real power of LangSwarm is orchestration. Here's how to make a **Researcher** and a **Writer** work together:

```python
from langswarm.core.agents import create_openai_agent, register_agent
from langswarm.core.workflows import create_simple_workflow, get_workflow_engine

# 1. Create specialized agents
researcher = create_openai_agent(id="researcher", model="gpt-4o")
writer = create_openai_agent(id="writer", model="gpt-4o")

# 2. Register them for orchestration
register_agent(researcher)
register_agent(writer)

# 3. Create a workflow: researcher ‚Üí writer
workflow = create_simple_workflow(
    workflow_id="content_pipeline",
    agent_chain=["researcher", "writer"]
)

# 4. Execute
engine = get_workflow_engine()
result = await engine.execute_workflow(
    workflow=workflow,
    input_data={"input": "Impact of AI on software development"}
)

print(f"Final Outcome: {result.output}")
```

---

## üìö **Next Steps**

- **[Core Architectural Patterns](../architecture/dual-interface-architecture)** - Understand how LangSwarm works.
- **[Memory Backends](../../user-guides/memory/postgresql)** - Setup PostgreSQL for enterprise memory.
- **[Using Tools](../../user-guides/tools/intent-based-calls)** - Give your agents real-world capabilities.
- **[API Reference](../../api-reference)** - Deep dive into classes and methods.

---

**üéâ Welcome to LangSwarm! You're ready to build the next generation of AI systems.**

# LangSwarm V1 to V2 Workflow Migration Guide

**Complete guide for migrating from V1's complex YAML-based workflows to V2's fluent builder API**

## ðŸŽ¯ Overview

LangSwarm V2 fundamentally transforms workflow creation from complex YAML configuration to intuitive, type-safe fluent APIs. This guide helps you migrate your existing V1 workflows to take advantage of V2's improved developer experience, better performance, and enhanced error handling.

**Migration Benefits:**
- **90% Simpler Creation**: YAML editing â†’ fluent builder API
- **100% Type Safety**: Runtime YAML validation â†’ compile-time checking
- **Better Performance**: 4 optimized execution modes vs 3 complex modes
- **Enhanced Debugging**: Step-by-step tracing vs hard-to-trace execution
- **Production Ready**: Comprehensive error handling and monitoring

---

## ðŸ”„ Migration Strategy

### **Phase 1: Assessment and Planning**
Analyze your existing V1 workflows and plan the migration approach.

```bash
# Find all workflow configurations in your codebase
find . -name "*.yaml" -o -name "*.yml" | grep -E "(workflow|flow)" 
grep -r "workflow_executor" your_project/
grep -r "WorkflowExecutor" your_project/
```

### **Phase 2: Compatibility Mode (Immediate)**
V2 provides YAML compatibility adapters during transition.

```python
# V1 YAML workflows continue working in V2
from langswarm.adapters import load_v1_workflow

# Load existing V1 YAML workflow
v1_workflow = load_v1_workflow("path/to/workflow.yaml")

# Execute with V2 engine
result = await execute_workflow_from_config(v1_workflow, inputs)
```

### **Phase 3: Native V2 Migration (Recommended)**
Convert to V2 fluent builder APIs for optimal experience.

```python
# V2 native workflow with fluent API
from langswarm.core.workflows import create_workflow

workflow = (create_workflow("migrated_workflow", "Migrated Analysis")
    .add_agent_step("extract", "data_extractor", "${input}")
    .add_agent_step("analyze", "analyzer", "${extract}")
    .add_transform_step("format", "${analyze}", format_function)
    .build())
```

---

## ðŸ“Š V1 vs V2 Comparison

### **Workflow Creation Comparison**

| Aspect | V1 YAML System | V2 Fluent API | Migration Impact |
|--------|----------------|---------------|------------------|
| **Configuration** | Complex YAML editing | Fluent builder API | 90% simpler creation |
| **Type Safety** | Runtime YAML validation | Compile-time checking | 100% type coverage |
| **IDE Support** | Limited YAML support | Full autocomplete | Better development experience |
| **Error Detection** | Runtime errors | Build-time validation | Earlier error detection |
| **Testing** | Difficult YAML testing | Easy mocking | 10x easier testing |
| **Debugging** | Hard to trace steps | Step-by-step monitoring | Much better debugging |
| **Performance** | 3 complex modes | 4 optimized modes | Better execution performance |

### **Developer Experience Improvements**

```python
# V1 YAML Configuration (Before)
workflow_config = """
workflows:
  data_analysis:
    name: "Data Analysis Pipeline"
    description: "Extract, analyze, and format data"
    timeout: 300
    retry_policy:
      max_retries: 3
      exponential_backoff: true
    error_strategy: "continue"
    
    steps:
      - id: extract
        type: agent
        agent_id: data_extractor
        input_template: "Extract data from: ${input}"
        timeout: 60
        depends_on: []
        
      - id: validate
        type: tool
        tool_name: data_validator
        tool_input: "${extract}"
        depends_on: [extract]
        
      - id: analyze
        type: agent
        agent_id: analyzer
        input_template: "Analyze: ${validate}"
        depends_on: [validate]
        timeout: 120
        
      - id: format
        type: transform
        function: format_results
        input: "${analyze}"
        depends_on: [analyze]
        
    variables:
      threshold: 0.8
      output_format: "json"
"""

# V2 Fluent API (After)
from langswarm.core.workflows import WorkflowBuilder

workflow = (WorkflowBuilder("data_analysis", "Data Analysis Pipeline")
    .set_description("Extract, analyze, and format data")
    .set_timeout(300)
    .set_retry_policy(max_retries=3, exponential_backoff=True)
    .set_error_strategy("continue")
    
    .add_variable("threshold", 0.8)
    .add_variable("output_format", "json")
    
    .add_agent_step("extract", "data_extractor", "Extract data from: ${input}", timeout_seconds=60)
    .add_tool_step("validate", "data_validator", "${extract}", depends_on=["extract"])
    .add_agent_step("analyze", "analyzer", "Analyze: ${validate}", depends_on=["validate"], timeout_seconds=120)
    .add_transform_step("format", "${analyze}", format_results, depends_on=["analyze"])
    
    .build())
```

---

## ðŸ› ï¸ Step-by-Step Migration

### **Step 1: Convert Basic Structure**

#### **V1 YAML Structure**
```yaml
# V1 workflow.yaml
workflows:
  simple_analysis:
    name: "Simple Data Analysis"
    steps:
      - id: extract
        type: agent
        agent_id: extractor
        input_template: "${input}"
      - id: analyze
        type: agent
        agent_id: analyzer
        input_template: "${extract}"
        depends_on: [extract]
```

#### **V2 Fluent API Equivalent**
```python
# V2 migration
from langswarm.core.workflows import WorkflowBuilder

workflow = (WorkflowBuilder("simple_analysis", "Simple Data Analysis")
    .add_agent_step("extract", "extractor", "${input}")
    .add_agent_step("analyze", "analyzer", "${extract}", depends_on=["extract"])
    .build())
```

### **Step 2: Migrate Complex Configurations**

#### **V1 Complex YAML**
```yaml
workflows:
  complex_pipeline:
    name: "Complex Processing Pipeline"
    timeout: 600
    retry_policy:
      max_retries: 5
      retry_delay: 2.0
      exponential_backoff: true
    error_strategy: "fail_fast"
    
    variables:
      confidence_threshold: 0.85
      batch_size: 100
      output_format: "structured"
    
    inputs:
      required: [data, config]
      optional: [metadata]
    
    steps:
      - id: preprocess
        type: tool
        tool_name: preprocessor
        tool_input: "${data}"
        tool_config:
          batch_size: "${batch_size}"
          format: "normalized"
        timeout: 120
        
      - id: parallel_analysis
        type: parallel_group
        steps:
          - id: sentiment
            type: agent
            agent_id: sentiment_analyzer
            input_template: "Analyze sentiment: ${preprocess}"
          - id: entities
            type: agent
            agent_id: entity_extractor
            input_template: "Extract entities: ${preprocess}"
          - id: topics
            type: agent
            agent_id: topic_extractor
            input_template: "Extract topics: ${preprocess}"
        depends_on: [preprocess]
        
      - id: quality_gate
        type: condition
        condition: "${sentiment.confidence} >= ${confidence_threshold}"
        true_step: "synthesis"
        false_step: "manual_review"
        depends_on: [parallel_analysis]
        
      - id: synthesis
        type: agent
        agent_id: synthesizer
        input_template: |
          Synthesize analysis results:
          Sentiment: ${sentiment}
          Entities: ${entities}
          Topics: ${topics}
        depends_on: [quality_gate]
        
      - id: manual_review
        type: agent
        agent_id: reviewer
        input_template: "Manual review needed: ${sentiment}, ${entities}, ${topics}"
        depends_on: [quality_gate]
        
      - id: format_output
        type: transform
        function: format_final_output
        input: "${synthesis || manual_review}"
        depends_on: [synthesis, manual_review]
```

#### **V2 Fluent API Migration**
```python
from langswarm.core.workflows import WorkflowBuilder
from langswarm.core.workflows.builder import ParallelWorkflowBuilder

# Main workflow
workflow = (WorkflowBuilder("complex_pipeline", "Complex Processing Pipeline")
    .set_timeout(600)
    .set_retry_policy(
        max_retries=5,
        retry_delay=2.0,
        exponential_backoff=True
    )
    .set_error_strategy("fail_fast")
    
    # Variables
    .add_variable("confidence_threshold", 0.85)
    .add_variable("batch_size", 100)
    .add_variable("output_format", "structured")
    
    # Required inputs
    .require_input("data")
    .require_input("config")
    
    # Preprocessing
    .add_tool_step("preprocess", "preprocessor", "${data}", 
                   tool_config={"batch_size": "${batch_size}", "format": "normalized"},
                   timeout_seconds=120)
    
    # Parallel analysis (V2 makes this much simpler)
    .add_parallel_group([
        ("sentiment", "sentiment_analyzer", "Analyze sentiment: ${preprocess}"),
        ("entities", "entity_extractor", "Extract entities: ${preprocess}"),
        ("topics", "topic_extractor", "Extract topics: ${preprocess}")
    ], depends_on=["preprocess"])
    
    # Quality gate
    .add_condition_step("quality_gate", 
                       "${sentiment.confidence} >= ${confidence_threshold}",
                       "synthesis", "manual_review")
    
    # Synthesis path
    .add_agent_step("synthesis", "synthesizer", 
                   """Synthesize analysis results:
                   Sentiment: ${sentiment}
                   Entities: ${entities}
                   Topics: ${topics}""",
                   depends_on=["quality_gate"])
    
    # Manual review path
    .add_agent_step("manual_review", "reviewer",
                   "Manual review needed: ${sentiment}, ${entities}, ${topics}",
                   depends_on=["quality_gate"])
    
    # Final formatting
    .add_transform_step("format_output", "${synthesis || manual_review}", 
                       format_final_output,
                       depends_on=["synthesis", "manual_review"])
    
    .build())
```

### **Step 3: Migrate Execution Patterns**

#### **V1 Execution**
```python
# V1 workflow execution
from langswarm.core.workflow_executor import WorkflowExecutor

executor = WorkflowExecutor()
executor.load_workflow_config("workflow.yaml")

# V1 execution modes
result = executor.execute("workflow_id", inputs, mode="sequential")
result = executor.execute("workflow_id", inputs, mode="parallel") 
result = executor.execute("workflow_id", inputs, mode="streaming")
```

#### **V2 Execution**
```python
# V2 workflow execution
from langswarm.core.workflows import execute_workflow, execute_workflow_stream

# V2 execution modes (cleaner and more intuitive)
result = await execute_workflow("workflow_id", inputs, mode="sync")      # Immediate
result = await execute_workflow("workflow_id", inputs, mode="async")     # Background
result = await execute_workflow("workflow_id", inputs, mode="parallel")  # Optimized parallel

# Streaming execution
async for step_result in execute_workflow_stream("workflow_id", inputs):
    print(f"Step {step_result.step_id}: {step_result.status}")
```

---

## ðŸ”§ Feature Migration

### **Error Handling Migration**

#### **V1 Error Handling**
```yaml
# V1 YAML error configuration
workflows:
  robust_workflow:
    error_strategy: "continue"
    retry_policy:
      max_retries: 3
      retry_delay: 1.0
    
    steps:
      - id: risky_step
        type: agent
        agent_id: risky_agent
        on_error:
          action: "retry"
          max_attempts: 5
        fallback:
          step_id: "backup_step"
```

#### **V2 Error Handling**
```python
# V2 fluent error handling
workflow = (WorkflowBuilder("robust_workflow")
    .set_error_strategy("continue")
    .set_retry_policy(max_retries=3, retry_delay=1.0)
    
    .add_agent_step("risky_step", "risky_agent", "${input}",
                   retry_count=5,
                   fallback_step="backup_step")
    
    .add_agent_step("backup_step", "backup_agent", "${input}")
    
    .build())
```

### **Variable System Migration**

#### **V1 Variables**
```yaml
# V1 YAML variables
workflows:
  templated_workflow:
    variables:
      user_name: "John Doe"
      threshold: 0.8
      settings:
        format: "json"
        verbose: true
    
    steps:
      - id: process
        type: agent
        agent_id: processor
        input_template: |
          Hello ${user_name},
          Process with threshold ${threshold}
          Settings: ${settings}
```

#### **V2 Variables**
```python
# V2 fluent variables
workflow = (WorkflowBuilder("templated_workflow")
    .add_variable("user_name", "John Doe")
    .add_variable("threshold", 0.8)
    .add_variable("settings", {"format": "json", "verbose": True})
    
    .add_agent_step("process", "processor", 
                   """Hello ${user_name},
                   Process with threshold ${threshold}
                   Settings: ${settings}""")
    
    .build())
```

### **Conditional Logic Migration**

#### **V1 Conditions**
```yaml
# V1 YAML conditions
steps:
  - id: quality_check
    type: condition
    condition:
      expression: "${score} >= ${threshold} and ${confidence} > 0.9"
      true_branch:
        step_id: "approve"
      false_branch:
        step_id: "review"
      
  - id: multi_condition
    type: multi_condition
    conditions:
      - condition: "${category} == 'urgent'"
        step_id: "urgent_process"
      - condition: "${category} == 'normal'"
        step_id: "normal_process"
      - default: "default_process"
```

#### **V2 Conditions**
```python
# V2 fluent conditions
workflow = (WorkflowBuilder("conditional_workflow")
    .add_condition_step("quality_check",
                       "${score} >= ${threshold} and ${confidence} > 0.9",
                       "approve", "review")
    
    # Multi-condition using chained conditions
    .add_condition_step("urgent_check", "${category} == 'urgent'", "urgent_process", "normal_check")
    .add_condition_step("normal_check", "${category} == 'normal'", "normal_process", "default_process")
    
    .build())
```

---

## ðŸ”„ Automated Migration Tools

### **YAML to Builder Converter**

```python
from langswarm.migration import convert_yaml_workflow

# Convert V1 YAML to V2 builder
with open("v1_workflow.yaml", "r") as f:
    v1_config = yaml.safe_load(f)

# Get V2 equivalent
v2_builder_code = convert_yaml_workflow(v1_config)
print(v2_builder_code)

# Output example:
"""
workflow = (WorkflowBuilder("data_analysis", "Data Analysis Pipeline")
    .add_agent_step("extract", "extractor", "${input}")
    .add_agent_step("analyze", "analyzer", "${extract}", depends_on=["extract"])
    .build())
"""
```

### **Migration Validation Tool**

```python
from langswarm.migration import validate_migration

# Validate that V2 workflow matches V1 behavior
v1_workflow = load_v1_workflow("v1_workflow.yaml")
v2_workflow = build_v2_workflow()

validation_result = validate_migration(v1_workflow, v2_workflow)

if validation_result.is_equivalent:
    print("âœ“ Migration successful - workflows are equivalent")
else:
    print("âš  Migration issues found:")
    for issue in validation_result.differences:
        print(f"  - {issue.description}")
        print(f"    V1: {issue.v1_value}")
        print(f"    V2: {issue.v2_value}")
```

### **Batch Migration Script**

```python
import os
import yaml
from langswarm.migration import migrate_workflow_directory

def migrate_all_workflows(source_dir, target_dir):
    """Migrate all V1 workflows to V2"""
    
    # Find all YAML workflow files
    yaml_files = []
    for root, dirs, files in os.walk(source_dir):
        for file in files:
            if file.endswith(('.yaml', '.yml')) and 'workflow' in file:
                yaml_files.append(os.path.join(root, file))
    
    print(f"Found {len(yaml_files)} workflow files to migrate")
    
    # Migrate each file
    for yaml_file in yaml_files:
        print(f"Migrating {yaml_file}...")
        
        try:
            # Convert to V2
            v2_code = convert_yaml_to_v2(yaml_file)
            
            # Write V2 Python file
            base_name = os.path.splitext(os.path.basename(yaml_file))[0]
            v2_file = os.path.join(target_dir, f"{base_name}_v2.py")
            
            with open(v2_file, 'w') as f:
                f.write(v2_code)
            
            print(f"  âœ“ Migrated to {v2_file}")
            
        except Exception as e:
            print(f"  âœ— Failed to migrate {yaml_file}: {e}")

# Run migration
migrate_all_workflows("./v1_workflows", "./v2_workflows")
```

---

## ðŸ§ª Testing Migration

### **V1 vs V2 Behavior Testing**

```python
import pytest
from langswarm.migration.testing import WorkflowMigrationTest

class TestWorkflowMigration(WorkflowMigrationTest):
    async def test_data_analysis_migration(self):
        """Test that V2 migration produces same results as V1"""
        
        # Load V1 workflow
        v1_workflow = self.load_v1_workflow("data_analysis.yaml")
        
        # Create V2 equivalent
        v2_workflow = (WorkflowBuilder("data_analysis", "Data Analysis")
            .add_agent_step("extract", "extractor", "${input}")
            .add_agent_step("analyze", "analyzer", "${extract}")
            .build())
        
        # Test inputs
        test_inputs = {"input": "Sample data for analysis"}
        
        # Execute both versions
        v1_result = await self.execute_v1_workflow(v1_workflow, test_inputs)
        v2_result = await execute_workflow("data_analysis", test_inputs)
        
        # Compare results
        self.assert_equivalent_results(v1_result, v2_result)
        
        # V2 should be faster due to optimizations
        assert v2_result.total_duration_ms <= v1_result.total_duration_ms
    
    async def test_parallel_execution_migration(self):
        """Test parallel execution migration"""
        
        # Inputs that can be processed in parallel
        inputs = {"data": ["item1", "item2", "item3"]}
        
        # V1 parallel execution
        v1_result = await self.execute_v1_parallel("parallel_workflow.yaml", inputs)
        
        # V2 parallel execution
        v2_result = await execute_workflow("parallel_workflow", inputs, mode="parallel")
        
        # Results should be equivalent
        self.assert_equivalent_results(v1_result, v2_result)
        
        # V2 should utilize parallelism better
        assert v2_result.metadata["parallel_efficiency"] >= v1_result.metadata.get("parallel_efficiency", 0)
```

### **Performance Comparison**

```python
import time
import asyncio

async def compare_performance():
    """Compare V1 vs V2 workflow performance"""
    
    inputs = {"data": "Performance test data"}
    
    # V1 Performance
    v1_times = []
    for i in range(10):
        start = time.time()
        v1_result = await execute_v1_workflow("test_workflow", inputs)
        v1_times.append(time.time() - start)
    
    # V2 Performance
    v2_times = []
    for i in range(10):
        start = time.time()
        v2_result = await execute_workflow("test_workflow", inputs)
        v2_times.append(time.time() - start)
    
    # Calculate metrics
    v1_avg = sum(v1_times) / len(v1_times)
    v2_avg = sum(v2_times) / len(v2_times)
    
    improvement = ((v1_avg - v2_avg) / v1_avg) * 100
    
    print(f"V1 average execution time: {v1_avg:.3f}s")
    print(f"V2 average execution time: {v2_avg:.3f}s")
    print(f"Performance improvement: {improvement:.1f}%")
    
    return {
        "v1_avg": v1_avg,
        "v2_avg": v2_avg,
        "improvement_percent": improvement
    }
```

---

## ðŸ“‹ Migration Checklist

### **Pre-Migration Assessment**
- [ ] Inventory all V1 YAML workflow files
- [ ] Document current workflow dependencies and integrations
- [ ] Identify custom step types and transformations
- [ ] Plan testing strategy for migrated workflows

### **Migration Implementation**
- [ ] Convert YAML structure to fluent builder API
- [ ] Migrate step configurations and dependencies
- [ ] Update variable and template systems
- [ ] Convert error handling and retry policies
- [ ] Update execution patterns and modes

### **Testing and Validation**
- [ ] Validate workflow configuration and dependencies
- [ ] Test execution with sample data
- [ ] Compare V1 vs V2 results for equivalence
- [ ] Verify performance improvements
- [ ] Test error handling and recovery scenarios

### **Production Deployment**
- [ ] Update workflow registration and discovery
- [ ] Monitor execution performance and reliability
- [ ] Verify integration with V2 agents and tools
- [ ] Update operational procedures and documentation

---

## ðŸŽ¯ Migration Success Metrics

### **Functionality Preservation**
- [ ] **100% Feature Parity**: All V1 functionality preserved or enhanced
- [ ] **Result Equivalence**: V2 workflows produce same results as V1
- [ ] **Error Handling**: All error scenarios handled correctly
- [ ] **Integration Compatibility**: Works with existing systems

### **Developer Experience Improvements**
- [ ] **90% Simpler Creation**: Fluent API vs YAML editing
- [ ] **Type Safety**: Compile-time validation vs runtime errors
- [ ] **IDE Support**: Full autocomplete and error detection
- [ ] **Testing**: Easier mocking and validation

### **Performance Enhancements**
- [ ] **Execution Speed**: Equal or better performance than V1
- [ ] **Parallel Optimization**: Better parallel execution efficiency
- [ ] **Resource Usage**: Lower memory and CPU overhead
- [ ] **Scalability**: Improved handling of large workflows

### **Operational Benefits**
- [ ] **Better Monitoring**: Step-by-step execution tracking
- [ ] **Easier Debugging**: Clear error messages and traces
- [ ] **Simplified Maintenance**: Cleaner code structure
- [ ] **Enhanced Reliability**: Robust error recovery

---

## ðŸš€ Post-Migration Optimization

### **Leverage V2 Features**
```python
# Take advantage of V2-specific improvements
workflow = (WorkflowBuilder("optimized_workflow")
    # Use V2 parallel optimization
    .add_parallel_group([
        ("analysis1", "analyzer1", "${input}"),
        ("analysis2", "analyzer2", "${input}"),
        ("analysis3", "analyzer3", "${input}")
    ])
    
    # Use V2 error recovery
    .set_error_strategy("continue_with_recovery")
    .add_recovery_step("cleanup", cleanup_function)
    
    # Use V2 monitoring
    .enable_detailed_monitoring()
    .set_performance_tracking(True)
    
    .build())
```

### **Performance Tuning**
```python
# Optimize for your specific use case
workflow = (WorkflowBuilder("tuned_workflow")
    # Optimize timeouts
    .set_timeout(180)  # Based on actual execution patterns
    
    # Tune retry policies
    .set_retry_policy(
        max_retries=2,  # Reduce unnecessary retries
        exponential_backoff=True,
        max_delay=30
    )
    
    # Enable caching for expensive operations
    .add_agent_step("expensive", "expensive_agent", "${input}",
                   cache_result=True, cache_ttl=3600)
    
    .build())
```

---

**The V2 workflow migration transforms complex YAML configuration into intuitive, type-safe APIs while preserving all functionality and adding powerful new capabilities for better performance and developer experience.**

---
title: "Memory System"
description: "Long-term persistence for agents"
---

# üß† Memory System

LangSwarm provides a unified memory system that handles:
- **Conversation History**: Auto-saving user and assistant messages.
- **Persistence**: Storing data across restarts (SQLite, Redis, ChromaDB).
- **Context Management**: Auto-summarization and token window management.

## üöÄ Quick Start

The easiest way to enable memory is through the Agent Builder.

```python
from langswarm.core.agents import AgentBuilder

# 1. Create agent with memory
agent = await (AgentBuilder("assistant")
    .openai()
    .model("gpt-4o")
    .memory_enabled(True)  # Enables In-Memory storage by default
    .max_history(10)       # Keep last 10 messages
    .build())

# 2. Chat with session_id
await agent.chat("My name is Alice", session_id="session_1")
await agent.chat("What is my name?", session_id="session_1")
# Output: "Your name is Alice."
```

## üíæ Persistence Backends

To save conversations to disk, you need to configure a `MemoryManager`.

### SQLite (Recommended for Local/Dev)

Perfect for local development and single-server deployments.

```python
from langswarm.core.memory import create_memory_manager

# 1. Configure Persistent Memory
memory_manager = create_memory_manager({
    "backend": "sqlite",
    "config": {
        "db_path": "./conversations.db"
    }
})

# 2. Attach to Agent
agent = await (AgentBuilder("persistent_agent")
    .openai()
    .memory_manager(memory_manager) 
    .build())
```

### Redis (Recommended for Production)

High-performance storage for distributed systems.

```python
memory_manager = create_memory_manager({
    "backend": "redis",
    "config": {
        "host": "localhost",
        "port": 6379,
        "ttl_seconds": 86400 # 24h expiration
    }
})
```

## üìö Advanced Features

### Vector Memory (RAG)

Integrate with Vector Databases like ChromaDB for semantic search over long-term history.

```python
from langswarm.core.memory import VectorMemoryManager

rag_memory = VectorMemoryManager(
    collection_name="agent_history",
    embedding_model="text-embedding-3-small"
)

agent = await (AgentBuilder("rag_agent")
    .memory_manager(rag_memory)
    .rag_enabled(True) # Retrieve relevant history before answering
    .build())
```

### Auto-Summarization

When conversation history exceeds the context window, LangSwarm can summarize it to save tokens.

```python
agent = await (AgentBuilder("long_runner")
    .openai()
    .memory_enabled(True)
    .max_tokens(4000)
    
    # Compress context when it hits 4000 tokens
    .auto_compress_context(True) 
    .build())
```

## üõ†Ô∏è Direct Memory Access

You can manually inspect or modify stored memory.

```python
# Get session history
history = await memory_manager.get_history("session_1")

for msg in history:
    print(f"[{msg.role}]: {msg.content}")

# Manually add a memory
await memory_manager.add_message(
    session_id="session_1",
    role="system",
    content="User prefers succinct answers."
)
```

---
title: "Agents"
description: "Building intelligence with specialized agents"
---

# ü§ñ Agents

Agents are the core building blocks of LangSwarm. Each agent is a specialized AI worker with a specific personality, toolset, and memory.

## üèóÔ∏è The Agent Builder

Use the fluent `AgentBuilder` to create agents in seconds. It handles configuration, defaults, and validation for you.

```python
from langswarm.core.agents import AgentBuilder

# 1. Create
agent = await (AgentBuilder("researcher")
    .openai()           # or .anthropic(), .gemini(), .litellm()
    .model("gpt-4o")
    .system_prompt("You are a senior technical researcher.")
    .temperature(0.7)
    .build())

# 2. Chat
response = await agent.chat("What are the key features of Python 3.12?")
print(response)
```

## üîå 1. Providers

LangSwarm supports all major LLM providers. Authentication is handled automatically via environment variables (e.g., `OPENAI_API_KEY`).

<CodeGroup>
```python OpenAI
# Uses OPENAI_API_KEY
await (AgentBuilder("gpt_agent")
    .openai()
    .model("gpt-4o")
    .build())
```

```python Anthropic
# Uses ANTHROPIC_API_KEY
await (AgentBuilder("claude_agent")
    .anthropic()
    .model("claude-3-opus")
    .max_tokens(4096)
    .build())
```

```python Gemini
# Uses GOOGLE_API_KEY
await (AgentBuilder("gemini_agent")
    .gemini()
    .model("gemini-pro")
    .build())
```

```python Local (Ollama)
# Connects to local Ollama instance
await (AgentBuilder("local_llama")
    .litellm()
    .model("ollama/llama3")
    .base_url("http://localhost:11434")
    .build())
```
</CodeGroup>

## üõ†Ô∏è 2. Tools

Give your agents superpowers by attaching tools. LangSwarm handles the tool schemas and execution.

```python
agent = await (AgentBuilder("math_wizard")
    .openai()
    .model("gpt-4o")
    .tools(["calculator", "web_search"]) # Enable specific tools
    .tool_choice("auto")                 # Let agent decide when to use them
    .build())

# The agent will automatically call the calculator tool
response = await agent.chat("Calculate the square root of 52948")
```

See the [Tools Guide](/user-guides/tools) for how to build custom tools.

## üß† 3. Memory

Enable persistence to let agents remember conversations across sessions.

```python
from langswarm.core.memory import create_memory_manager

# Create a persistent SQLite memory
memory = create_memory_manager("sqlite", db_path="./memory.db")
await memory.backend.connect()

agent = await (AgentBuilder("friend")
    .openai()
    .model("gpt-4o")
    .memory_manager(memory)  # Attach memory manager
    .build())

# Chat with a session ID
await agent.chat("My name is Alex.", session_id="user_123")
# ... later ...
await agent.chat("What is my name?", session_id="user_123")  # "Your name is Alex."
```

## ‚ö° 4. Streaming

Stream responses in real-time for a better user experience.

```python
agent = await (AgentBuilder("streamer").openai().model("gpt-4o").build())

async for chunk in agent.chat_stream("Write a long poem about rust"):
    print(chunk, end="", flush=True)
```

## üß© Advanced Features

<CardGroup cols={2}>
    <Card title="Observability" icon="magnifying-glass-chart">
        ```python
        .litellm()
        .observability("langfuse")
        ```
        Trace execution and costs.
    </Card>
    <Card title="Vision" icon="eye">
        ```python
        .vision_enabled(True)
        ```
        Process images directly in chat.
    </Card>
    <Card title="JSON Mode" icon="brackets-curly">
        ```python
        .response_format("json_object")
        ```
        Force strictly valid JSON output.
    </Card>
    <Card title="Failover" icon="shield-check">
        ```python
        .failover(["gpt-4o", "claude-3-opus"])
        ```
        Auto-retry with backup models.
    </Card>
</CardGroup>
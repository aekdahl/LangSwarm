# Global BigQuery Memory for All Workflow Agents
# =============================================
#
# This configuration shows how to capture ALL agent interactions
# in a single BigQuery dataset without configuring each agent individually.

version: "1.0"

# =============================================================================
# GLOBAL MEMORY CONFIGURATION
# =============================================================================
# ðŸŽ¯ This memory configuration applies to ALL agents automatically
memory:
  backend: "bigquery"
  settings:
    project_id: "enkl-uat"  # Your Google Cloud project
    dataset_id: "langswarm_workflows"
    table_id: "unified_agent_conversations"
    location: "US"
    
    # Optional: Enhanced tracking
    description: "Unified memory for all workflow agents"
    retention_days: 90
    clustering_fields: ["session_id", "agent_id"]

# =============================================================================
# SESSION CONFIGURATION (Optional)
# =============================================================================
# Ensures all agents in a workflow share the same session context
session:
  unified_memory: true
  session_strategy: "workflow_scoped"
  session_timeout: 3600  # 1 hour session timeout

# =============================================================================
# AGENTS (No individual memory config needed!)
# =============================================================================
agents:
  # Data Processing Agent
  - id: "data_processor"
    model: "gpt-4o"
    behavior: "analytical"
    system_prompt: |
      You are a data processing specialist. 
      Analyze incoming data and prepare it for further processing.
      You have access to shared workflow memory.

  # Content Summarizer Agent
  - id: "summarizer"
    model: "gpt-4o"
    behavior: "helpful"
    system_prompt: |
      You are a content summarizer.
      Create concise summaries of processed data.
      You can see the full workflow history in your memory.

  # Quality Validator Agent  
  - id: "validator"
    model: "gpt-4o"
    behavior: "analytical"
    system_prompt: |
      You are a quality validator.
      Review and validate the work of previous agents.
      Access the complete workflow context from memory.

  # Report Generator Agent
  - id: "reporter"
    model: "gpt-4o"
    behavior: "helpful"
    system_prompt: |
      You are a report generator.
      Create comprehensive reports based on the full workflow.
      Use memory to reference all previous agent interactions.

# =============================================================================
# WORKFLOWS
# =============================================================================
workflows:
  # Multi-agent data processing workflow
  - id: "data_analysis_workflow"
    name: "Complete Data Analysis Pipeline"
    steps:
      - id: "process_data"
        agent: "data_processor"
        input: "${user_input}"
        output:
          to: "processing_result"

      - id: "summarize_findings"
        agent: "summarizer" 
        input: "Summarize these findings: ${context.step_outputs.process_data}"
        output:
          to: "summary_result"

      - id: "validate_work"
        agent: "validator"
        input: "Validate this analysis and summary: ${context.step_outputs.summary_result}"
        output:
          to: "validation_result"

      - id: "generate_report"
        agent: "reporter"
        input: "Generate a comprehensive report based on all previous work"
        output:
          to: "user"

  # Research and analysis workflow
  - id: "research_workflow"
    name: "Research and Analysis Pipeline"
    steps:
      - id: "initial_research"
        agent: "data_processor"
        input: "Research: ${user_input}"

      - id: "analysis"
        agent: "validator"
        input: "Analyze the research findings"

      - id: "final_summary"
        agent: "summarizer"
        input: "Create final summary of research and analysis"
        output:
          to: "user"

# =============================================================================
# USAGE EXAMPLES
# =============================================================================

# Python Usage:
# from langswarm.core.config import LangSwarmConfigLoader
# 
# loader = LangSwarmConfigLoader("global_bigquery_workflow_example.yaml")
# workflows, agents, brokers, tools, metadata = loader.load()
# 
# # Execute workflow - all agent interactions saved to BigQuery
# executor = WorkflowExecutor(workflows, agents)
# result = executor.run_workflow("data_analysis_workflow", user_input="Analyze sales data for Q4 2024")

# =============================================================================
# BIGQUERY ANALYTICS AFTER WORKFLOWS RUN
# =============================================================================

# Query 1: See complete workflow execution
# SELECT 
#   session_id,
#   agent_id,
#   timestamp,
#   LEFT(user_input, 100) as input_preview,
#   LEFT(agent_response, 100) as response_preview
# FROM `enkl-uat.langswarm_workflows.unified_agent_conversations`
# WHERE session_id = 'your-session-id'
# ORDER BY timestamp;

# Query 2: Workflow performance analytics
# SELECT 
#   session_id,
#   COUNT(*) as agent_interactions,
#   MIN(timestamp) as workflow_start,
#   MAX(timestamp) as workflow_end,
#   TIMESTAMP_DIFF(MAX(timestamp), MIN(timestamp), SECOND) as duration_seconds
# FROM `enkl-uat.langswarm_workflows.unified_agent_conversations`
# GROUP BY session_id
# ORDER BY workflow_start DESC;

# Query 3: Agent usage patterns
# SELECT 
#   agent_id,
#   COUNT(*) as total_interactions,
#   COUNT(DISTINCT session_id) as workflows_participated,
#   AVG(LENGTH(agent_response)) as avg_response_length
# FROM `enkl-uat.langswarm_workflows.unified_agent_conversations`
# WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
# GROUP BY agent_id;

# Query 4: Error analysis
# SELECT 
#   session_id,
#   agent_id,
#   timestamp,
#   text
# FROM `enkl-uat.langswarm_workflows.unified_agent_conversations`
# WHERE LOWER(text) LIKE '%error%' 
#    OR LOWER(agent_response) LIKE '%error%'
# ORDER BY timestamp DESC;